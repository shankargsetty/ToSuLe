{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f25894e",
   "metadata": {},
   "source": [
    "# EDA Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedb210",
   "metadata": {},
   "source": [
    "## Supervised Learning - Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead85796",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", color_codes=True)\n",
    "\n",
    "iris = pd.read_csv(\"./datasets/Iris.csv\") # the iris dataset is now a Pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many examples in each species\n",
    "iris[\"Species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b07fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observe scatterplot of the Iris features\n",
    "iris.plot(kind=\"scatter\", x=\"SepalLengthCm\", y=\"SepalWidthCm\", color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ef697",
   "metadata": {},
   "source": [
    "### A seaborn jointplot - bivariate scatterplots and univariate histograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13915b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the seaborn library to make a similar plot\n",
    "# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\n",
    "sns.jointplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", data=iris, height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f68d66",
   "metadata": {},
   "source": [
    "### Seaborn's FacetGrid - to color the scatterplot by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6370f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One piece of information missing in the plots above is what species each plant is\n",
    "# We'll use seaborn's FacetGrid to color the scatterplot by species\n",
    "sns.FacetGrid(iris, hue=\"Species\", height=5) \\\n",
    "   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n",
    "   .add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7006dd",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9401e",
   "metadata": {},
   "source": [
    "- **Boxplots** are a great tool for data visualisation.\n",
    "- Boxplots can be used to:\n",
    "    - To understand the distribution (spread/range) of the data\n",
    "    - To determine if data is skewed or not\n",
    "    - Identify outliers or anomalous data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b640659",
   "metadata": {},
   "source": [
    "<img src=\"images/boxplot.png\"> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16903b93",
   "metadata": {},
   "source": [
    "#### Box plots are non-parametric: they display variation in samples of a statistical population without making any assumptions of the underlying statistical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178aa817",
   "metadata": {},
   "source": [
    "#### Simple box plot using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['SepalWidthCm'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef206d14",
   "metadata": {},
   "source": [
    "#### Boxplots with Logarithmic Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08431f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing logarithmically scaled data\n",
    "\n",
    "iris['SepalWidthCm'].plot(kind='box')\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da7ee2",
   "metadata": {},
   "source": [
    "#### Making Boxplots Horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd58e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rotating the box plot so it is horizontal\n",
    "iris['SepalLengthCm'].plot(kind='box', vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b946c8f",
   "metadata": {},
   "source": [
    "#### Displaying all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying all columns in the dataframe on a single figure\n",
    "iris.plot(kind='box');\n",
    "plt.semilogy();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a642b",
   "metadata": {},
   "source": [
    "### Seaborn Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9472b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at an individual feature in Seaborn through a boxplot\n",
    "sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way we can extend this plot is adding a layer of individual points on top of\n",
    "# it through Seaborn's striplot\n",
    "# \n",
    "# We'll use jitter=True so that all the points don't fall in single vertical lines\n",
    "# above the species\n",
    "#\n",
    "# Saving the resulting axes as ax each time causes the resulting plot to be shown\n",
    "# on top of the previous axes\n",
    "ax = sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)\n",
    "ax = sns.stripplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, jitter=True, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174de44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68619c13",
   "metadata": {},
   "source": [
    "### Seaborn Violin plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ed9ce",
   "metadata": {},
   "source": [
    " - A violin plot combines the benefits of the previous two plots and simplifies them\n",
    " - Denser regions of the data are fatter, and sparser thiner in a violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"PetalLengthCm\", data=iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83820f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.violinplot(x=\"SepalWidthCm\", data=iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b77e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tune bandwidth\n",
    "ax = sns.violinplot(x=\"SepalWidthCm\", data=iris, bw=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A violin plot combines the benefits of the previous two plots and simplifies them\n",
    "# Denser regions of the data are fatter, and sparser thiner in a violin plot\n",
    "sns.violinplot(x=\"Species\", y=\"PetalWidthCm\", data=iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f374fc8",
   "metadata": {},
   "source": [
    "### kdeplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a50f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A final seaborn plot useful for looking at univariate relations is the kdeplot,\n",
    "# which creates and visualizes a kernel density estimate of the underlying feature\n",
    "sns.FacetGrid(iris, hue=\"Species\", height=6) \\\n",
    "   .map(sns.kdeplot, \"PetalLengthCm\") \\\n",
    "   .add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b83ffd1",
   "metadata": {},
   "source": [
    "### Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b1d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another useful seaborn plot is the pairplot, which shows the bivariate relation\n",
    "# between each pair of features\n",
    "# \n",
    "# From the pairplot, we'll see that the Iris-setosa species is separataed from the other\n",
    "# two across all feature combinations\n",
    "sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", height=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The diagonal elements in a pairplot show the kde by default\n",
    "# We can update these elements to show other things, such as a histogram\n",
    "sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", height=3, diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a911923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've covered seaborn, let's go back to some of the ones we can make with Pandas\n",
    "# We can quickly make a boxplot with Pandas on each feature split out by species\n",
    "iris.drop(\"Id\", axis=1).boxplot(by=\"Species\", figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc7d0c",
   "metadata": {},
   "source": [
    "## Start here for building logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3de9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b62e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REVIST this CELL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e89d39",
   "metadata": {},
   "source": [
    "#### Taking the first two features - X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc3276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ## code here\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ed570",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769a4cb",
   "metadata": {},
   "source": [
    "#### Lable Encoding for Species attribute - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labels = iris['Species']\n",
    "\n",
    "# Label encoding for the categorical data \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3c844",
   "metadata": {},
   "source": [
    " - `sklearn.model_selection`  - train test split of data; \n",
    " - `sklearn.linear_model` - logestic regression model for target prediction\n",
    " - `sklearn.metrics` - model evaluation, performace measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec4144",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13102db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e748fc",
   "metadata": {},
   "source": [
    "#### Predicting the test set results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d49b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c37ac",
   "metadata": {},
   "source": [
    "#### Confusion Matrix with an example\n",
    "- **TN:** A person who is actually not pregnant (negative) and classified as not pregnant (negative).\n",
    "- **TP:** A person who is actually pregnant (positive) and classified as pregnant (positive).\n",
    "- **FP:** A person who is actually not pregnant (negative) and classified as pregnant (positive)\n",
    "- **FN:** A person who is actually pregnant (positive) and classified as not pregnant (negative).\n",
    "- Consider in **100** people **40** are pregnant and the remaining **60** people are not but have fat belly.\n",
    "- Out of **40** pregnant women **30** pregnant women are classified correctly and the remaining **10** pregnant women are classified as not pregnant.\n",
    "- Out of **60** people in the not pregnant category, **55** are classified as not pregnant and the remaining **5** are classified as pregnant.\n",
    "\n",
    "<img src = './images/confusion_matrix.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d4883",
   "metadata": {},
   "source": [
    "*  **[Q]** What is the **accuracy** of the machine learning model for this classification task?\n",
    "* **[A] Accuracy** = $\\frac{(TP + TN)} {(TP + TN + FP + FN)} = 0.85$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9542de68",
   "metadata": {},
   "source": [
    "* **[Q]** Is accuracy the best measure?\n",
    "* **[A]** Accuracy is not good measure if the data is not balanced (**Data Imbalancing**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df996feb",
   "metadata": {},
   "source": [
    "#### Data Imbalancing Problem\n",
    "- Consider **90** people who are healthy (negative) and **10** people who have some disease (positive).\n",
    "- Learning model perfectly classifies the **90** people as healthy but it also classifies the unhealthy people as healthy. (i.e., TN = 90, FP = 0, FN = 10 and TP = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ff28a",
   "metadata": {},
   "source": [
    "* **[Q]** What is the accuracy of the machine learning model for this classification task?\n",
    "* **[A] Accuracy** = $\\frac{(TP + TN)} {(TP + TN + FP + FN)} = 0.9$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc425b3",
   "metadata": {},
   "source": [
    "* **[Q]** Is there anything fishy?\n",
    "* **[A]** Accuracy is **90%** but this model is very poor because all the **10** people who are unhealthy are classified as healthy.\n",
    "* **Inference:** Thus accuracy is not a good metric when the data set is unbalanced.\n",
    "* There are another set of good metric which are derived from the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c3ebb7",
   "metadata": {},
   "source": [
    "<img src = './images/confusion_matrix1.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250acc8",
   "metadata": {},
   "source": [
    "* **Precision** should ideally be 1 (high) for a good classifier. (In our example Precision = 0.857)\n",
    "* **Recall** should ideally be 1 (high) for a good classifier. (In our example Recall = 0.75)\n",
    "* Thus, **F1 score** is the harmonic mean of precision and recall and is a better measure than accuracy. ( In our example F1 = 0.799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4765292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bff2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = #code here\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d3591",
   "metadata": {},
   "source": [
    "The result is telling us that we have 16+13+8 correct predictions and 0+13+0 incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b013ab",
   "metadata": {},
   "source": [
    "#### Caculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df79b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f19e7",
   "metadata": {},
   "source": [
    "#### Compute precision, recall, F-measure and support\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
    "\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07546a",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5c672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
